{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0: Getting Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Python version: 3.8.12 (default, Oct 12 2021, 06:23:56) \n",
      "[Clang 10.0.0 ]\n",
      "### Numpy version: 1.19.5\n",
      "### Scikit-learn version: 1.0.1\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('### Python version: ' + sys.version)\n",
    "print('### Numpy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "\n",
    "# load our packages / code\n",
    "sys.path.insert(1, '../common/')\n",
    "import utils\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "\n",
    "seed = 42 # deterministic seed\n",
    "\n",
    "np.random.seed(seed) \n",
    "\n",
    "# 80% training, 20% testing\n",
    "train_prop = 0.8\n",
    "test_prop = 1.0 - train_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# For this exercise, we'll load a dataset directly from scikit-learn\n",
    "iris = load_iris()\n",
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "\n",
    "all_x = iris['data']\n",
    "all_y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the classes and features?\n",
    "# 'target_names' and 'feature_names' fields in 'iris'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Classes: {}'.format(classes))\n",
    "print('Features: {}'.format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape to know what we are getting\n",
    "print(all_x.shape, all_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use only two classes ('versicolor', 'virginica')\n",
    "class1_idx = 1\n",
    "class2_idx = 2\n",
    "\n",
    "sel_classes = [classes[class1_idx], classes[class2_idx]]\n",
    "\n",
    "versicolor_label = 1\n",
    "virginica_label = 2\n",
    "\n",
    "# keep only examples of these two classes\n",
    "sel_idx_1 = np.where(all_y == versicolor_label)[0]\n",
    "sel_idx_2 = np.where(all_y == virginica_label)[0]\n",
    "\n",
    "sel_idx = np.r_[sel_idx_1, sel_idx_2]\n",
    "# Note: we could use np.hstack((sel_idx_1, sel_idx_2)) instead\n",
    "\n",
    "sel_x = all_x[sel_idx,:]\n",
    "sel_y = all_y[sel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and grab only the last two features (i.e., 'petal length' (idx 2), 'petal_width' (idx 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "proc_x = sel_x[:, [feature1_idx, feature2_idx]]\n",
    "proc_y = sel_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck the shapes\n",
    "print(proc_x.shape, proc_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(proc_x, proc_y, train_size=train_prop, test_size=test_prop, \n",
    "                                                        random_state=seed)# set the random state to our seed for reproducibility "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check the shapes of train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the (training) data look like?\n",
    "train_x[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the data look like?\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's train our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "## ref: https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "model = SVC(kernel='linear', random_state=seed).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to show classifier's decision boundary and training examples\n",
    "title = 'SVM Classifier (with linear kernel)'\n",
    "\n",
    "# we use matplotlib for this\n",
    "fig, ax = plt.subplots(figsize=(10,6)) # create a new figure\n",
    "\n",
    "# grab the training data features\n",
    "X0, X1 = train_x[:, 0], train_x[:, 1]\n",
    "\n",
    "# make a grid so we can plot the decision regions and boundaries (see plots.py for implementation of countours)\n",
    "xx, yy = plots.make_meshgrid(X0, X1, h=0.01)\n",
    "plots.contours(ax, model, xx, yy, cmap=plt.cm.coolwarm, alpha=0.75)\n",
    "\n",
    "# now plot the training data points in a scatter plot with color according to the labels (train_y)\n",
    "scatter = ax.scatter(X0, X1, c=train_y, cmap=plt.cm.coolwarm, s=75, linewidth=2, edgecolors='k')\n",
    "\n",
    "# set limits, labels, title\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xlabel(features[feature1_idx])\n",
    "ax.set_ylabel(features[feature2_idx])\n",
    "ax.set_title(title)\n",
    "\n",
    "# legend\n",
    "handles, labels = scatter.legend_elements()\n",
    "ax.legend(handles, sel_classes, loc=\"upper right\", title=\"Classes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "pred_y = model.predict(test_x)\n",
    "\n",
    "# are those prediction correct?\n",
    "from sklearn import metrics\n",
    "\n",
    "# use scikit-learn to compute accuracy for us (metrics.accuracy_score) on the test data\n",
    "\n",
    "print('Model accuracy: {:.2f}%'.format(acc_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on *training* set\n",
    "pred_y = model.predict(train_x)\n",
    "\n",
    "acc_score = metrics.accuracy_score(train_y, pred_y)\n",
    "print('Training accuracy: {:.2f}%'.format(acc_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: Is the model overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
